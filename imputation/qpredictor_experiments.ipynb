{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0zE1diBlVeRO",
    "outputId": "4f6aed34-0daa-4926-8eb9-7d8862be68b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 397134062\n",
      "2022-05-15 16:36:59,839 [INFO]: Generating mask with base p=0.0\n",
      "2022-05-15 16:36:59,961 [INFO]: ----------------------------------------------------------------------------------------------------\n",
      "Hyperparameters:\n",
      "quantile_lower      : 0.025\n",
      "quantile_upper      : 0.975\n",
      "seed                : 397134062\n",
      "precision           : 32\n",
      "model_name          : grin\n",
      "dataset_name        : la_point\n",
      "config              : grin.yaml\n",
      "p_fault             : 0.0\n",
      "p_noise             : 0.0\n",
      "in_sample           : False\n",
      "val_len             : 0.1\n",
      "test_len            : 0.2\n",
      "lr                  : 0.001\n",
      "l2_reg              : 0.0\n",
      "epochs              : 300\n",
      "batches_per_epoch   : 160\n",
      "patience            : 50\n",
      "grad_clip_val       : 5.0\n",
      "use_lr_schedule     : True\n",
      "save_preds          : False\n",
      "neptune_logger      : False\n",
      "project_name        : sandbox\n",
      "tags                : ()\n",
      "hidden_size         : 64\n",
      "ff_size             : 64\n",
      "embedding_size      : 8\n",
      "n_layers            : 1\n",
      "n_nodes             : None\n",
      "kernel_size         : 2\n",
      "decoder_order       : 1\n",
      "layer_norm          : False\n",
      "dropout             : 0\n",
      "ff_dropout          : 0\n",
      "merge_mode          : mlp\n",
      "window              : 24\n",
      "stride              : 100\n",
      "window_lag          : 1\n",
      "horizon_lag         : 1\n",
      "batch_size          : 32\n",
      "mask_scaling        : True\n",
      "workers             : 12\n",
      "scale_target        : True\n",
      "whiten_prob         : 0.05\n",
      "prediction_loss_weight: 1.0\n",
      "impute_only_missing : True\n",
      "warm_up_steps       : (0, 0)\n",
      "hpc_exp_number      : None\n",
      "\n",
      "2022-05-15 16:36:59,983 [INFO]: Inferred input data-format: [steps, nodes, channels]\n",
      "2022-05-15 16:36:59,983 [INFO]: Inferred input data-format: [steps, nodes, channels]\n",
      "2022-05-15 16:36:59,984 [INFO]: Inferred input data-format: [steps, nodes, channels]\n",
      "2022-05-15 16:37:00,026 [INFO]: Scaler for data: StandardScaler(bias=(1, 1, 1), scale=(1, 1, 1))\n",
      "/Users/usi/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:261: UserWarning: Attribute 'loss_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_fn'])`.\n",
      "  rank_zero_warn(\n",
      "/Users/usi/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py:91: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|████████████████████| 3/3 [00:51<00:00, 17.32s/it]\n",
      "Predicting DataLoader 0: 100%|████████████████████| 3/3 [00:51<00:00, 17.31s/it]\n",
      "2022-05-15 16:38:44,045 [INFO]: [], []\n",
      "2022-05-15 16:38:44,069 [INFO]: ('center:', {'test_mae': 2.3236842, 'test_mre': 0.03994844319962133, 'test_mape': 0.050818246, 'test_picp': 0.9268737563564006, 'test_mpiw': 6.5952506})\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|████████████████████| 3/3 [00:49<00:00, 16.60s/it]\n",
      "Predicting DataLoader 0: 100%|████████████████████| 3/3 [00:49<00:00, 16.56s/it]\n",
      "2022-05-15 16:40:23,621 [INFO]: ('uniform:', {'test_mae': 3.177906292760836, 'test_mre': 0.05463410709382932, 'test_mape': 0.06939967362627733, 'test_picp': 0.9268737563564006, 'test_mpiw': 6.5952506})\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|████████████████████| 3/3 [00:50<00:00, 16.74s/it]\n",
      "Predicting: 0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "!python3 -u qpredictor_experiments.py --quantile-lower=0.025 --quantile-upper=0.975 --workers=12 --stride=100"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "run_imputation_modified.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
